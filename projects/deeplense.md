---
layout: single
title: Foundation Model
permalink: /projects/deeplense/
author_profile: false
---

## **Specific Test VI - Foundation Model**  

This folder contains my solution for **Specific Test VI: Foundation Model** of the DeepLense GSoC 2025 project. The task involves pretraining a **Masked Autoencoder (MAE)** on strong lensing images and fine-tuning it for **multi-class classification** and **super-resolution** using **PyTorch**.  

### ğŸ“Œ **Task Overview**  
The test consists of two main parts:  
1. **Pretraining a Masked Autoencoder (MAE)** on **no_sub** samples to learn meaningful feature representations.  
2. **Fine-tuning the MAE**:  
   - For **multi-class classification** (distinguishing between no_sub, cdm, and axion).  
   - For **super-resolution** (upscaling low-resolution images using high-resolution ground truths).  

#### ğŸ“· Sample Images for Each Task
- **Samples for multi-class classification**
   ![Sample Images](/waleedAlzamil80.github.io/assets/deeplense/classification/classSample.png)
 
- **Samples for super-resolution**
   ![Sample Images](/waleedAlzamil80.github.io/assets/deeplense/superresolution/superRsample.png)

### ğŸ“‚ **Folder Structure**  
```
specific_test_06/
â”‚â”€â”€ models/                        # ğŸ“‚ Model definitions & weights
â”‚   â”œâ”€â”€ mae.py                      # MAE model
â”‚   â”œâ”€â”€ classifier.py                # Classification model
â”‚   â”œâ”€â”€ super_resolution.py         # Super-Resolution model
â”‚   â”œâ”€â”€ checkpoints/                 # Trained weights
â”‚       â”œâ”€â”€ mae.pth
â”‚       â”œâ”€â”€ classifier.pth
â”‚       â”œâ”€â”€ super_resolution.pth
â”‚
â”‚â”€â”€ scripts/                        # ğŸ“‚ Training & evaluation scripts NOTE the parameters here are hardcoded
â”‚   â”œâ”€â”€ train_mae.py                 # Train MAE
â”‚   â”œâ”€â”€ train_classifier.py          # Train classification model
â”‚   â”œâ”€â”€ train_superresolution.py           # Train super-resolution model
â”‚   â”œâ”€â”€ evaluate.py                  # Compute MSE, SSIM, PSNR, LPIPS # not created yet
â”‚   â”œâ”€â”€ infer.py                     # Run inference on new images # not ready
â”‚   â”œâ”€â”€ infer_01.py                  # Run inference on new images Classification # not ready
â”‚
â”‚â”€â”€ utils/                          # ğŸ“‚ Helper functions
â”‚   â”œâ”€â”€ Dataset.py                    # Data loading & augmentation
â”‚   â”œâ”€â”€ metrics.py                    # SSIM, PSNR, LPIPS calculations
â”‚   â”œâ”€â”€ helpful.py                    # helpful functions that's used alot
â”‚   â”œâ”€â”€ vis.py                        # save plots like pca and tsne
â”‚   â”œâ”€â”€ extract_encoderPart.py        # take parts from the trained mae model to be used for fine-tuning models
â”‚
â”‚â”€â”€ /waleedAlzamil80.github.io/assets/deeplense/                        # ğŸ“‚ Store evaluation results
â”‚   â”œâ”€â”€ mae/                                   # Images
â”‚   â”œâ”€â”€ classification/                        # Images
â”‚   â”œâ”€â”€ superresolution/                       # Images
â”‚
â”‚â”€â”€ notebooks/                      # ğŸ“‚ Jupyter notebooks
â”‚   â”œâ”€â”€ mae_training.ipynb                     # Training MAE step-by-step
â”‚   â”œâ”€â”€ classification_training.ipynb          # Fine-tuning classifier
â”‚   â”œâ”€â”€ super_resolution_training.ipynb        # Fine-tuning super-resolution
â”‚
â”‚â”€â”€ requirements.txt                 # ğŸ“œ Dependencies
â”‚â”€â”€ README.md                         # ğŸ“œ Project overview
â”‚â”€â”€ .gitignore                        # ğŸš« Ignore large files (checkpoints, datasets)
```

### **Prepate Data for Masked Autoencoder (MAE) Pretraining**  

#### **Input for Encoder**
- **Sample for splitted-image**
   ![Sample Images](/waleedAlzamil80.github.io/assets/deeplense/mae/splitted_image.png)

- **Sample for masked-image**
   ![Sample Images](/waleedAlzamil80.github.io/assets/deeplense/mae/masked_image.png)

- **Masked pathces and Visible patches**

   | ![Masked Image](/waleedAlzamil80.github.io/assets/deeplense/mae/masked_patches.png) | ![EncoderInput](/waleedAlzamil80.github.io/assets/deeplense/mae/visible_patches.png) |
   |------------|-------------|


### ğŸ›  **Model and Approach**  
#### **1ï¸âƒ£ Masked Autoencoder (MAE) Pretraining**
- **Goal:** Learn a feature representation of strong lensing images.  
- **Architecture:** Vision Transformer (ViT) backbone with a reconstruction head.  
- **Pretraining Loss:** Mean Squared Error (MSE)
- **Optimizer:** AdamW 
- **Batch Size:** *256*
- **Epochs:** *250*

#### **2ï¸âƒ£ Fine-Tuning for Multi-Class Classification**
- **Loss Function:** Cross-Entropy Loss  
- **Optimizer:** AdamW 
- **Batch Size:** *256*
- **Evaluation Metrics:** AUC Score, Accuracy  
- **Epochs:** *250*

#### **3ï¸âƒ£ Fine-Tuning for Super-Resolution**
- **Loss Function:** Mean Squared Error (MSE)
- **Batch Size:** *256*
- **Evaluation Metrics:** MSE, SSIM, PSNR  
- **Epochs:** *200*
- **NOTE** The Decoder used here is not suitable for images and especially for super-resolution tasks. So we need more work on the architecture

### ğŸ“Š **Results**  
Below are the evaluation results for each task:  

#### **1ï¸âƒ£ Masked Autoencoder (MAE) Pretraining**  
- **Training Loss (MSE) over 250 epochs**  
  ![MAE Loss](/waleedAlzamil80.github.io/assets/deeplense/mae/MAE_Losses.png)  
- **PCA and TSNE on the embedding**  
  - Hidder representation:  
    | ![pca](/waleedAlzamil80.github.io/assets/deeplense/mae/pca_plot.png) | ![tsne](/waleedAlzamil80.github.io/assets/deeplense/mae/tsne_plot.png) |
    |------------|------------|

#### **2ï¸âƒ£ Multi-Class Classification**  
- **Accuracy & AUC Score over epochs**  
    | ![Accuracy Metrics](/waleedAlzamil80.github.io/assets/deeplense/classification/Accuracies.png) | ![AUC Metrics](/waleedAlzamil80.github.io/assets/deeplense/classification/AUC.png) |
    |------------|------------|

- **Classification Report**
```
              precision    recall  f1-score   support

      no_sub       0.97      0.99      0.98      2945
       axion       0.98      0.97      0.97      2990
         cdm       0.97      0.95      0.96      2976

    accuracy                           0.97      8911
   macro avg       0.97      0.97      0.97      8911
weighted avg       0.97      0.97      0.97      8911
```

- **Confusion Matrix and ROC Curve**
    | ![ROC Metrics](/waleedAlzamil80.github.io/assets/deeplense/classification/ROC_curve.png) | ![Confusion Matrix](/waleedAlzamil80.github.io/assets/deeplense/classification/confusion_matrix.png) |
    |------------|------------|

- **PCA & tsne plotting**
    | ![PCA](/waleedAlzamil80.github.io/assets/deeplense/classification/pca_plot.png) | ![tsne](/waleedAlzamil80.github.io/assets/deeplense/classification/tsne_plot.png) |
    |------------|------------|

#### **3ï¸âƒ£ Super-Resolution**
- **MSE as a loss, SSIM, PSNR over epochs**
      | ![SSIM](/waleedAlzamil80.github.io/assets/deeplense/superresolution/SSIM.png) | ![PSNR](/waleedAlzamil80.github.io/assets/deeplense/superresolution/PSNR.png) |
    |------------|------------|
  ![MSE](/waleedAlzamil80.github.io/assets/deeplense/superresolution/MAE_Losses.png)

- **Final Metrics** *these results from best SSIM model **superresolution_SSIM** and it's very close to **superresolution_PSNR***
     - Final Validation MSE: 0.002293
     - Final Validation PSNR: 29.62
     - Final Validation SSIM: 0.9190
##### **Interpretation**

- Lower **MSE** means better reconstruction (less error).
- If MSE = 0, the images are identical.

- Higher **PSNR** means better quality.
- **Typical values:**
  - **30-50 dB** â†’ Good quality
  - **20-30 dB** â†’ Moderate quality
  - **<20 dB** â†’ Poor quality
- If PSNR â†’ âˆ, it means the images are **identical** (MSE = 0).

- **SSIM = 1** â†’ Identical images.
- **SSIM close to 0** â†’ No structural similarity.
- Unlike MSE and PSNR, **SSIM aligns more with human perception**.

- **Super-resolution comparison**  
  - Low-res, predicted high-res, and ground truth  
    | ![LR](/waleedAlzamil80.github.io/assets/deeplense/superresolution/lr_image.png) | ![Predicted](/waleedAlzamil80.github.io/assets/deeplense/superresolution/superResoluted.png) | ![HR](/waleedAlzamil80.github.io/assets/deeplense/superresolution/hr_image.png) |
    |------------|------------|-------------|

### ğŸš€ **Running the Code**  
1. Open any `*.ipynb` in Jupyter Notebook.
2. Run all cells to train the models.
3. Model checkpoints will be saved in `*.pth`.

### ğŸ“¬ **Submission Details**
This task is part of my DeepLense GSoC 2025 submission.